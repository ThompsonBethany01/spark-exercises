{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate() #method to create spark session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "### 1. The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name\n",
       "0      python\n",
       "1        html\n",
       "2        java\n",
       "3       swift\n",
       "4         c++\n",
       "5  javascript"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = pd.DataFrame({'name': ['python','html','java','swift','c++','javascript']})\n",
    "\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = spark.createDataFrame(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "language.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no index in spark\n",
    "language.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|python|\n",
      "|  html|\n",
      "|  java|\n",
      "| swift|\n",
      "|   c++|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "language.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data('mpg'))\n",
    "\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create 1 column of output that contains a message like the one below:\n",
    "    - The 1999 audi a4 has a 4 cylinder engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|string                                                      |\n",
      "+------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a6cylinder engine.                     |\n",
      "|The 1999 audi a4 has a6cylinder engine.                     |\n",
      "|The 2008 audi a4 has a6cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a6cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a6cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a8cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a8cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a8cylinder engine.|\n",
      "+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(concat(lit('The '), mpg.year, lit(' '), mpg.manufacturer, lit(' '), mpg.model, lit(' has a'), mpg.cyl, lit('cylinder engine.')).alias('string')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each vehicle.\n",
    "    - Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|     trans| trans|\n",
      "+----------+------+\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|manual(m6)|manual|\n",
      "|  auto(av)|  auto|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(av)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m6)|manual|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(l5)|  auto|\n",
      "|manual(m5)|manual|\n",
      "|  auto(s6)|  auto|\n",
      "|manual(m6)|manual|\n",
      "|  auto(l5)|  auto|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(s6)|  auto|\n",
      "|  auto(l4)|  auto|\n",
      "|  auto(l4)|  auto|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.trans,\n",
    "          when((mpg.trans.contains('auto')), 'auto')\n",
    "          .otherwise('manual')\n",
    "          .alias('trans')).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Load the tips dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = spark.createDataFrame(data('tips'))\n",
    "\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.114754098360656 percent of observations are smokers.\n"
     ]
    }
   ],
   "source": [
    "print((tips.filter(tips.smoker == 'Yes').count() / tips.count() * 100), 'percent of observations are smokers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = tips.select(\n",
    "        tips.total_bill, tips.tip, tips.sex, tips.smoker, tips.day, tips.time, tips.size,\n",
    "        (tips.total_bill / tips.tip).alias('tip_percent')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|       tip_percent|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2| 16.82178217821782|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3| 6.228915662650603|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3| 6.002857142857144|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|7.1540785498489425|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4| 6.811634349030471|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|   sex|smoker|  avg(tip_percent)|\n",
      "+------+------+------------------+\n",
      "|  Male|  null|  7.23406046621358|\n",
      "|Female|   Yes| 6.448210654922861|\n",
      "|  Male|   Yes| 8.117240108903532|\n",
      "|  null|  null| 7.048932200195785|\n",
      "|Female|    No| 6.877796519255278|\n",
      "|  Male|    No|6.6877637800136105|\n",
      "|Female|  null| 6.714850156922292|\n",
      "+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.rollup('sex','smoker').agg(avg(tips.tip_percent)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = spark.createDataFrame(data.seattle_weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert the temperatures to farenheight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.withColumn(\n",
    "    \"temp_max\", (col(\"temp_max\") * 9 / 5 + 32)\n",
    ").withColumn(\"temp_min\", (col(\"temp_min\") * 9 / 5 + 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"month\", \"year\")\n",
    "    .agg(sum(\"precipitation\").alias(\"total_monthly_precipitation\"))\n",
    "    .groupBy(\"month\")\n",
    "    .agg(mean(\"total_monthly_precipitation\").alias(\"avg_monthly_rain\"))\n",
    "    .sort(col(\"avg_monthly_rain\").desc())\n",
    "    .first()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(year=2012, total_winds=1244.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_winds\"))\n",
    "    .sort(col(\"total_winds\").desc())\n",
    "    .first()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(col(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|average_high_temp| average_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(col(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           avg(rain)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measure a rainy day by weather == rain\n",
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          avg(rain)|\n",
      "+-------------------+\n",
      "|0.18478260869565216|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measure a rainy day by precipitation > 0\n",
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
